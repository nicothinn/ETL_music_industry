{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard Design for Merged Music Dataset (Spotify, Billboard, Grammys)\n",
    "\n",
    "This document outlines a data-driven approach for designing a Power BI dashboard using a dataset created through left joins between Spotify (audio features), Billboard (chart performance), and Grammy Awards (award nominations and categories).\n",
    "\n",
    "---\n",
    "\n",
    "## Available Variables\n",
    "\n",
    "### Spotify Audio Features\n",
    "- `popularity`: Popularity score assigned by Spotify\n",
    "- `explicit`: Boolean flag indicating explicit lyrics\n",
    "- `tempo`, `valence`, `energy`, `danceability`, `acousticness`: Numeric features describing musical properties\n",
    "- `duration_minutes`: Track duration in minutes\n",
    "- `track_genre`: Music genre classification\n",
    "\n",
    "### Grammy Awards Metadata\n",
    "- `year`: Year of the Grammy edition\n",
    "- `category`: Award category (e.g., Song of the Year)\n",
    "\n",
    "### Billboard Chart Data\n",
    "- `first_chart_date`: Date the song first appeared on the Billboard Hot 100\n",
    "- `billboard_peak`: Best chart position achieved\n",
    "- `total_weeks_on_chart`: Number of weeks the song remained on the chart\n",
    "\n",
    "---\n",
    "\n",
    "## Analytical Goals and Visualizations\n",
    "\n",
    "| Goal                                       | Recommended Chart Type                        |\n",
    "|--------------------------------------------|-----------------------------------------------|\n",
    "| Explore correlations between features      | Scatter plots (e.g., popularity vs peak rank) |\n",
    "| Compare genres and musical characteristics | Boxplots or violin plots by `track_genre`     |\n",
    "| Analyze Grammy award distribution          | Stacked bar chart (songs by year/category)    |\n",
    "| Map genre to award category relationships  | Heatmap or matrix of `track_genre` vs `category` |\n",
    "| Identify temporal trends                   | Line charts using `first_chart_date`          |\n",
    "| Compare multivariate success factors       | Bubble plots (e.g., popularity vs weeks on chart) |\n",
    "| Measure data source coverage               | Bar chart of counts grouped by source overlap |\n",
    "\n",
    "---\n",
    "\n",
    "## Recommended KPIs for Power BI Cards\n",
    "\n",
    "- Maximum `popularity`\n",
    "- Highest `total_weeks_on_chart`\n",
    "- Most common `track_genre` among Grammy-nominated songs\n",
    "- Count of songs with and without Billboard or Grammy data\n",
    "\n",
    "---\n",
    "\n",
    "## Data Join Strategy Summary\n",
    "\n",
    "- A left join ensures that all Spotify songs are retained\n",
    "- Billboard and Grammy data are merged only when a `song_name` (and `artist` for Billboard) match\n",
    "- This design allows the dashboard to reflect both enriched records and those available only in Spotify\n",
    "\n",
    "---\n",
    "\n",
    "## Power BI Visualizations to Implement\n",
    "\n",
    "1. Scatter plot: Popularity vs Billboard peak\n",
    "2. Violin plot: Popularity distribution by genre\n",
    "3. Stacked bar chart: Number of Grammy-nominated songs per year\n",
    "4. Matrix: Track genre vs Grammy category\n",
    "5. Line chart: Billboard presence over time by genre\n",
    "6. Bubble chart: Popularity vs total weeks on chart\n",
    "7. Bar chart: Count of songs by source coverage (Spotify only, +Grammy, +Billboard)\n",
    "8. KPI cards: Top popularity, longest chart presence, most common genre, data source match summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "dbname   = os.environ.get(\"DB_NAME\")\n",
    "user     = os.environ.get(\"DB_USER\")\n",
    "password = os.environ.get(\"DB_PASSWORD\")\n",
    "host     = os.environ.get(\"DB_HOST\")\n",
    "port     = os.environ.get(\"DB_PORT\")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=dbname,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.grammy_awards (\n",
    "    year INTEGER,\n",
    "    title TEXT,\n",
    "    published_at TEXT,\n",
    "    updated_at TEXT,\n",
    "    category TEXT,\n",
    "    nominee TEXT,\n",
    "    artist TEXT,\n",
    "    workers TEXT,\n",
    "    img TEXT,\n",
    "    winner BOOLEAN\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "csv_file_path = '../data/raw/the_grammy_awards.csv'\n",
    "\n",
    "copy_query = \"\"\"\n",
    "COPY public.grammy_awards FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "\"\"\"\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as f:\n",
    "    cur.copy_expert(copy_query, f)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57302\\AppData\\Local\\Temp\\ipykernel_39636\\4080410312.py:36: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  df = pl.DataFrame(rows, schema=columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billboard data extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def extract_spotify():\n",
    "    df = pl.read_csv(\"../data/raw/spotify_dataset.csv\")\n",
    "    df.write_csv(\"../data/raw/spotify_dataset2.csv\")\n",
    "\n",
    "def extract_grammys():\n",
    "    load_dotenv()\n",
    "\n",
    "    dbname = os.getenv(\"DB_NAME\")\n",
    "    user = os.getenv(\"DB_USER\")\n",
    "    password = os.getenv(\"DB_PASSWORD\")\n",
    "    host = os.getenv(\"DB_HOST\")\n",
    "    port = os.getenv(\"DB_PORT\")\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=dbname,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        host=host,\n",
    "        port=port\n",
    "    )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM public.grammy_awards;\")\n",
    "    columns = [desc[0] for desc in cur.description]\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    df = pl.DataFrame(rows, schema=columns)\n",
    "    df.write_csv(\"../data/raw/grammy_awards_full.csv\")\n",
    "\n",
    "def extract_billboard():\n",
    "    url = \"https://raw.githubusercontent.com/mhollingshead/billboard-hot-100/main/all.json\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        charts = response.json()\n",
    "        all_data = []\n",
    "\n",
    "        for chart in charts:\n",
    "            chart_date = chart[\"date\"]\n",
    "            for entry in chart[\"data\"]:\n",
    "                all_data.append({\n",
    "                    \"date\": chart_date,\n",
    "                    \"rank\": entry.get(\"this_week\"),\n",
    "                    \"title\": entry.get(\"song\"),\n",
    "                    \"artist\": entry.get(\"artist\"),\n",
    "                    \"last_week\": entry.get(\"last_week\"),\n",
    "                    \"peak_position\": entry.get(\"peak_position\"),\n",
    "                    \"weeks_on_chart\": entry.get(\"weeks_on_chart\")\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df.to_csv(\"../data/raw/billboard_full_chart_data.csv\", index=False)\n",
    "        print(\"Billboard data extracted successfully!\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch chart data. Status code: {response.status_code}\")\n",
    "\n",
    "extract_spotify()\n",
    "extract_grammys()\n",
    "extract_billboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trasform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import re\n",
    "\n",
    "DATA_RAW = \"../data/raw\"\n",
    "DATA_PROCESSED = \"../data/processed\"\n",
    "\n",
    "def normalize_text(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.lower()\n",
    "        value = re.sub(r\"[^a-z0-9\\s;]\", \"\", value)\n",
    "        value = re.sub(r\"\\s+\", \" \", value)\n",
    "        return value.strip()\n",
    "    return value\n",
    "\n",
    "def transform_spotify():\n",
    "    df = pl.read_csv(f\"{DATA_RAW}/spotify_dataset2.csv\")\n",
    "    df = df.rename({col: col.strip().lower().replace(\" \", \"_\") for col in df.columns})\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"track_name\").map_elements(normalize_text, return_dtype=pl.Utf8),\n",
    "        pl.col(\"artists\").map_elements(normalize_text, return_dtype=pl.Utf8)\n",
    "    ])\n",
    "\n",
    "    df = df.select([\n",
    "        pl.col(\"track_name\").alias(\"song_name\"),\n",
    "        pl.col(\"artists\").alias(\"artist\"),\n",
    "        \"track_genre\",\n",
    "        \"popularity\",\n",
    "        \"explicit\",\n",
    "        \"tempo\",\n",
    "        \"valence\",\n",
    "        \"energy\",\n",
    "        \"danceability\",\n",
    "        \"acousticness\",\n",
    "        \"duration_ms\"\n",
    "    ])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"duration_ms\") / 60000).alias(\"duration_minutes\")\n",
    "    ])\n",
    "\n",
    "    df.write_csv(f\"{DATA_PROCESSED}/spotify_transformed.csv\")\n",
    "\n",
    "def transform_grammys():\n",
    "    df = pl.read_csv(f\"{DATA_RAW}/grammy_awards_full.csv\")\n",
    "    df = df.rename({col: col.strip().lower().replace(\" \", \"_\") for col in df.columns})\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"nominee\").map_elements(normalize_text, return_dtype=pl.Utf8),\n",
    "        pl.col(\"artist\").map_elements(normalize_text, return_dtype=pl.Utf8),\n",
    "        pl.col(\"category\").map_elements(normalize_text, return_dtype=pl.Utf8)\n",
    "    ])\n",
    "\n",
    "    df = df.filter(\n",
    "        (pl.col(\"category\").str.contains(\"song\") | pl.col(\"category\").str.contains(\"record\")) &\n",
    "        ~(pl.col(\"category\").str.contains(\"album\") | pl.col(\"category\").str.contains(\"artist\"))\n",
    "    )\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"nominee\").alias(\"song_name\")\n",
    "    ])\n",
    "\n",
    "    df.write_csv(f\"{DATA_PROCESSED}/grammys_transformed.csv\")\n",
    "\n",
    "def transform_billboard():\n",
    "    df = pl.read_csv(f\"{DATA_RAW}/billboard_full_chart_data.csv\")\n",
    "    df = df.rename({col: col.strip().lower().replace(\" \", \"_\") for col in df.columns})\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"title\").map_elements(normalize_text, return_dtype=pl.Utf8),\n",
    "        pl.col(\"artist\").map_elements(normalize_text, return_dtype=pl.Utf8)\n",
    "    ])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"title\").alias(\"song_name\"),\n",
    "        pl.col(\"date\").str.slice(0, 4).cast(pl.Int64).alias(\"first_year_on_chart\")\n",
    "    ])\n",
    "\n",
    "    df.write_csv(f\"{DATA_PROCESSED}/billboard_transformed.csv\")\n",
    "\n",
    "def transform_all_datasets():\n",
    "    transform_spotify()\n",
    "    transform_grammys()\n",
    "    transform_billboard()\n",
    "\n",
    "transform_all_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "DATA_PROCESSED = \"../data/processed\"\n",
    "\n",
    "def merge_datasets():\n",
    "    df_spotify = pl.read_csv(f\"{DATA_PROCESSED}/spotify_transformed.csv\")\n",
    "    df_grammys = pl.read_csv(f\"{DATA_PROCESSED}/grammys_transformed.csv\")\n",
    "    df_billboard = pl.read_csv(f\"{DATA_PROCESSED}/billboard_transformed.csv\")\n",
    "\n",
    "    df_spotify = df_spotify.unique()\n",
    "    df_grammys = df_grammys.unique()\n",
    "    df_billboard = df_billboard.unique()\n",
    "\n",
    "    df_spotify = df_spotify.with_columns([\n",
    "        (pl.col(\"song_name\") + \"|\" + pl.col(\"artist\")).alias(\"merge_key\")\n",
    "    ]).sort(\"popularity\", descending=True)\n",
    "\n",
    "    df_spotify = df_spotify.group_by(\"merge_key\").agg([\n",
    "        pl.col(\"song_name\").first(),\n",
    "        pl.col(\"artist\").first(),\n",
    "        pl.col(\"track_genre\").unique().alias(\"track_genres\"),\n",
    "        pl.col(\"popularity\").first(),\n",
    "        pl.col(\"explicit\").first(),\n",
    "        pl.col(\"tempo\").first(),\n",
    "        pl.col(\"valence\").first(),\n",
    "        pl.col(\"energy\").first(),\n",
    "        pl.col(\"danceability\").first(),\n",
    "        pl.col(\"acousticness\").first(),\n",
    "        pl.col(\"duration_minutes\").first()\n",
    "    ])\n",
    "\n",
    "    df_spotify = df_spotify.with_columns([\n",
    "        pl.col(\"track_genres\").list.join(\", \").alias(\"track_genre\")\n",
    "    ]).drop(\"track_genres\")\n",
    "\n",
    "    df_grammys = df_grammys.sort(\"year\", descending=True)\n",
    "    df_grammys = df_grammys.group_by(\"song_name\").agg([\n",
    "        pl.col(\"year\").first(),\n",
    "        pl.col(\"category\").first(),\n",
    "        pl.col(\"published_at\").first()\n",
    "    ])\n",
    "\n",
    "    df_billboard = df_billboard.with_columns([\n",
    "        (pl.col(\"song_name\") + \"|\" + pl.col(\"artist\")).alias(\"merge_key\")\n",
    "    ])\n",
    "\n",
    "    df_billboard_grouped = df_billboard.group_by(\"merge_key\").agg([\n",
    "        pl.col(\"date\").min().alias(\"first_chart_date\"),\n",
    "        pl.col(\"rank\").min().alias(\"billboard_peak\"),\n",
    "        pl.col(\"weeks_on_chart\").sum().alias(\"total_weeks_on_chart\"),\n",
    "        pl.col(\"first_year_on_chart\").min()\n",
    "    ])\n",
    "\n",
    "    merged = df_spotify.join(df_grammys, on=\"song_name\", how=\"left\")\n",
    "    merged = merged.join(df_billboard_grouped, on=\"merge_key\", how=\"left\")\n",
    "\n",
    "    merged = merged.drop(\"merge_key\")\n",
    "\n",
    "    columns_to_drop = [\n",
    "        \"duration_ms\",\n",
    "        \"nominee\",\n",
    "        \"artist_grammy\",\n",
    "        \"workers\",\n",
    "        \"img\",\n",
    "        \"winner\",\n",
    "        \"first_year_on_chart\",\n",
    "        \"billboard_artist\",\n",
    "        \"updated_at\",\n",
    "        \"title\",\n",
    "        \"published_at\"\n",
    "    ]\n",
    "    existing_to_drop = [col for col in columns_to_drop if col in merged.columns]\n",
    "    merged = merged.drop(existing_to_drop)\n",
    "\n",
    "    merged.write_csv(f\"{DATA_PROCESSED}/final_dataset.csv\")\n",
    "\n",
    "merge_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>song_name</th><th>artist</th><th>popularity</th><th>explicit</th><th>tempo</th><th>valence</th><th>energy</th><th>danceability</th><th>acousticness</th><th>duration_minutes</th><th>track_genre</th><th>year</th><th>category</th><th>first_chart_date</th><th>billboard_peak</th><th>total_weeks_on_chart</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;parachute&quot;</td><td>&quot;porya hatami&quot;</td><td>5</td><td>false</td><td>68.976</td><td>0.0486</td><td>0.0892</td><td>0.355</td><td>0.975</td><td>2.93345</td><td>&quot;iranian&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;danny trejo&quot;</td><td>&quot;plastilina mosh&quot;</td><td>25</td><td>true</td><td>93.984</td><td>0.756</td><td>0.968</td><td>0.771</td><td>0.288</td><td>4.003333</td><td>&quot;afrobeat&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;atak gaya arijit singh&quot;</td><td>&quot;arijit singh;rupali moghe&quot;</td><td>74</td><td>false</td><td>80.568</td><td>0.508</td><td>0.366</td><td>0.4</td><td>0.87</td><td>3.32345</td><td>&quot;pop, pop-film&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;places&quot;</td><td>&quot;martin solveig;ina wroldsen&quot;</td><td>62</td><td>false</td><td>121.995</td><td>0.62</td><td>0.854</td><td>0.728</td><td>0.248</td><td>3.379083</td><td>&quot;house, disco, edm&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;oh my gawd feat nicki minaj k4…</td><td>&quot;mr eazi;major lazer;nicki mina…</td><td>45</td><td>false</td><td>94.018</td><td>0.834</td><td>0.866</td><td>0.82</td><td>0.152</td><td>3.0</td><td>&quot;dancehall&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 16)\n",
       "┌────────────┬───────────┬───────────┬──────────┬───┬──────────┬───────────┬───────────┬───────────┐\n",
       "│ song_name  ┆ artist    ┆ popularit ┆ explicit ┆ … ┆ category ┆ first_cha ┆ billboard ┆ total_wee │\n",
       "│ ---        ┆ ---       ┆ y         ┆ ---      ┆   ┆ ---      ┆ rt_date   ┆ _peak     ┆ ks_on_cha │\n",
       "│ str        ┆ str       ┆ ---       ┆ bool     ┆   ┆ str      ┆ ---       ┆ ---       ┆ rt        │\n",
       "│            ┆           ┆ i64       ┆          ┆   ┆          ┆ str       ┆ i64       ┆ ---       │\n",
       "│            ┆           ┆           ┆          ┆   ┆          ┆           ┆           ┆ i64       │\n",
       "╞════════════╪═══════════╪═══════════╪══════════╪═══╪══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ parachute  ┆ porya     ┆ 5         ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
       "│            ┆ hatami    ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│ danny      ┆ plastilin ┆ 25        ┆ true     ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
       "│ trejo      ┆ a mosh    ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│ atak gaya  ┆ arijit    ┆ 74        ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
       "│ arijit     ┆ singh;rup ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│ singh      ┆ ali moghe ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│ places     ┆ martin    ┆ 62        ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
       "│            ┆ solveig;i ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│            ┆ na        ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│            ┆ wroldsen  ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│ oh my gawd ┆ mr eazi;m ┆ 45        ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
       "│ feat nicki ┆ ajor laze ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│ minaj k4…  ┆ r;nicki   ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "│            ┆ mina…     ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴──────────┴───┴──────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv(\"../data/processed/final_dataset.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage of Spotify Songs in Billboard and Grammy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.76% of Spotify songs also appear in the Billboard dataset.\n",
      "0.59% were nominated for the Grammys.\n"
     ]
    }
   ],
   "source": [
    "total_songs = df.select(pl.len()).item()\n",
    "billboard_count = df.filter(pl.col(\"billboard_peak\").is_not_null()).select(pl.len()).item()\n",
    "grammy_count = df.filter(pl.col(\"category\").is_not_null()).select(pl.len()).item()\n",
    "\n",
    "billboard_pct = round((billboard_count / total_songs) * 100, 2)\n",
    "grammy_pct = round((grammy_count / total_songs) * 100, 2)\n",
    "\n",
    "print(f\"{billboard_pct}% of Spotify songs also appear in the Billboard dataset.\")\n",
    "print(f\"{grammy_pct}% were nominated for the Grammys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (78_441, 16)\n",
      "┌────────────┬───────────┬───────────┬──────────┬───┬──────────┬───────────┬───────────┬───────────┐\n",
      "│ song_name  ┆ artist    ┆ popularit ┆ explicit ┆ … ┆ category ┆ first_cha ┆ billboard ┆ total_wee │\n",
      "│ ---        ┆ ---       ┆ y         ┆ ---      ┆   ┆ ---      ┆ rt_date   ┆ _peak     ┆ ks_on_cha │\n",
      "│ str        ┆ str       ┆ ---       ┆ bool     ┆   ┆ str      ┆ ---       ┆ ---       ┆ rt        │\n",
      "│            ┆           ┆ i64       ┆          ┆   ┆          ┆ str       ┆ i64       ┆ ---       │\n",
      "│            ┆           ┆           ┆          ┆   ┆          ┆           ┆           ┆ i64       │\n",
      "╞════════════╪═══════════╪═══════════╪══════════╪═══╪══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ unholy     ┆ sam       ┆ 100       ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ feat kim   ┆ smith;kim ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ petras     ┆ petras    ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ quevedo    ┆ bizarrap; ┆ 99        ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ bzrp music ┆ quevedo   ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ sessions   ┆           ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ vo…        ┆           ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ la bachata ┆ manuel    ┆ 98        ┆ false    ┆ … ┆ null     ┆ 2022-09-0 ┆ 67        ┆ 231       │\n",
      "│            ┆ turizo    ┆           ┆          ┆   ┆          ┆ 3         ┆           ┆           │\n",
      "│ im good    ┆ david gue ┆ 98        ┆ true     ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ blue       ┆ tta;bebe  ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│            ┆ rexha     ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ tit me     ┆ bad bunny ┆ 97        ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ pregunt    ┆           ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ …          ┆ …         ┆ …         ┆ …        ┆ … ┆ …        ┆ …         ┆ …         ┆ …         │\n",
      "│ angels we  ┆ jim       ┆ 0         ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ have heard ┆ brickman  ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ on high    ┆           ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ breathe    ┆ catie     ┆ 0         ┆ true     ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│            ┆ turner    ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ suite for  ┆ john rutt ┆ 0         ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ strings    ┆ er;perrys ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ excerpts   ┆ burg high ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ iii…       ┆ sc…       ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ pennies    ┆ louis     ┆ 0         ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ from       ┆ prima;sam ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ heaven     ┆ butera    ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│            ┆ the wit…  ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "│ stay       ┆ cole      ┆ 0         ┆ false    ┆ … ┆ null     ┆ null      ┆ null      ┆ null      │\n",
      "│ downtown   ┆ swindell  ┆           ┆          ┆   ┆          ┆           ┆           ┆           │\n",
      "└────────────┴───────────┴───────────┴──────────┴───┴──────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir cuántas canciones populares quieres ver\n",
    "top_n = 30\n",
    "\n",
    "# Ordenar por popularidad descendente y seleccionar las primeras\n",
    "most_popular = df.sort(\"popularity\", descending=True)\n",
    "\n",
    "# Mostrar en notebook\n",
    "print(most_popular)\n",
    "\n",
    "# Guardar en CSV\n",
    "most_popular.write_csv(\"../data/processed/most_popular.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with all columns filled: 89\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_csv(\"../data/processed/final_dataset.csv\")\n",
    "fully_filled = df.filter(\n",
    "    pl.all_horizontal([pl.col(c).is_not_null() for c in df.columns])\n",
    ")\n",
    "\n",
    "print(f\"Number of rows with all columns filled: {fully_filled.shape[0]}\")\n",
    "\n",
    "fully_filled.write_csv(\"../data/processed/fully_filled_rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>song_name</th><th>artist</th><th>popularity</th><th>explicit</th><th>tempo</th><th>valence</th><th>energy</th><th>danceability</th><th>acousticness</th><th>duration_minutes</th><th>track_genre</th><th>year</th><th>category</th><th>first_chart_date</th><th>billboard_peak</th><th>total_weeks_on_chart</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;just the way you are&quot;</td><td>&quot;billy joel&quot;</td><td>72</td><td>false</td><td>139.148</td><td>0.513</td><td>0.453</td><td>0.589</td><td>0.703</td><td>4.842883</td><td>&quot;songwriter, piano, singer-song…</td><td>1978</td><td>&quot;song of the year&quot;</td><td>&quot;1977-11-12&quot;</td><td>3</td><td>378</td></tr><tr><td>&quot;lonely boy&quot;</td><td>&quot;the black keys&quot;</td><td>73</td><td>false</td><td>166.3</td><td>0.607</td><td>0.872</td><td>0.356</td><td>0.00417</td><td>3.22755</td><td>&quot;garage, blues, punk, punk-rock&quot;</td><td>2012</td><td>&quot;best rock song&quot;</td><td>&quot;2011-11-12&quot;</td><td>64</td><td>210</td></tr><tr><td>&quot;carry on&quot;</td><td>&quot;xxxtentacion&quot;</td><td>75</td><td>true</td><td>147.899</td><td>0.383</td><td>0.197</td><td>0.735</td><td>0.768</td><td>2.162</td><td>&quot;emo&quot;</td><td>1997</td><td>&quot;best dance recording&quot;</td><td>&quot;2017-09-16&quot;</td><td>95</td><td>1</td></tr><tr><td>&quot;truth hurts&quot;</td><td>&quot;lizzo&quot;</td><td>1</td><td>true</td><td>158.088</td><td>0.407</td><td>0.622</td><td>0.715</td><td>0.11</td><td>2.88875</td><td>&quot;hip-hop&quot;</td><td>2019</td><td>&quot;song of the year&quot;</td><td>&quot;2019-05-18&quot;</td><td>1</td><td>903</td></tr><tr><td>&quot;youre still the one&quot;</td><td>&quot;shania twain&quot;</td><td>78</td><td>false</td><td>133.822</td><td>0.634</td><td>0.494</td><td>0.585</td><td>0.363</td><td>3.536667</td><td>&quot;country&quot;</td><td>1998</td><td>&quot;best country song&quot;</td><td>&quot;1998-02-14&quot;</td><td>2</td><td>903</td></tr><tr><td>&quot;tears in heaven&quot;</td><td>&quot;eric clapton&quot;</td><td>66</td><td>false</td><td>153.744</td><td>0.312</td><td>0.242</td><td>0.498</td><td>0.835</td><td>4.529333</td><td>&quot;blues&quot;</td><td>1992</td><td>&quot;record of the year&quot;</td><td>&quot;1992-02-08&quot;</td><td>2</td><td>351</td></tr><tr><td>&quot;you make me feel like dancing&quot;</td><td>&quot;leo sayer&quot;</td><td>60</td><td>false</td><td>96.071</td><td>0.705</td><td>0.731</td><td>0.734</td><td>0.0784</td><td>3.688433</td><td>&quot;disco&quot;</td><td>1977</td><td>&quot;best rhythm blues song&quot;</td><td>&quot;1976-10-23&quot;</td><td>1</td><td>231</td></tr><tr><td>&quot;good life&quot;</td><td>&quot;onerepublic&quot;</td><td>74</td><td>true</td><td>94.988</td><td>0.645</td><td>0.69</td><td>0.634</td><td>0.0771</td><td>4.221767</td><td>&quot;rock, piano&quot;</td><td>2007</td><td>&quot;best rap song&quot;</td><td>&quot;2009-11-28&quot;</td><td>8</td><td>630</td></tr><tr><td>&quot;after the love has gone&quot;</td><td>&quot;earth wind fire&quot;</td><td>67</td><td>false</td><td>131.675</td><td>0.391</td><td>0.443</td><td>0.424</td><td>0.532</td><td>4.634</td><td>&quot;disco&quot;</td><td>1979</td><td>&quot;best rhythm blues song&quot;</td><td>&quot;1979-07-07&quot;</td><td>2</td><td>153</td></tr><tr><td>&quot;lean on me&quot;</td><td>&quot;bill withers&quot;</td><td>70</td><td>false</td><td>75.143</td><td>0.426</td><td>0.22</td><td>0.619</td><td>0.782</td><td>4.3139</td><td>&quot;soul&quot;</td><td>1987</td><td>&quot;best rhythm blues song&quot;</td><td>&quot;1972-04-22&quot;</td><td>1</td><td>190</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 16)\n",
       "┌───────────┬───────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ song_name ┆ artist    ┆ popularit ┆ explicit ┆ … ┆ category  ┆ first_cha ┆ billboard ┆ total_wee │\n",
       "│ ---       ┆ ---       ┆ y         ┆ ---      ┆   ┆ ---       ┆ rt_date   ┆ _peak     ┆ ks_on_cha │\n",
       "│ str       ┆ str       ┆ ---       ┆ bool     ┆   ┆ str       ┆ ---       ┆ ---       ┆ rt        │\n",
       "│           ┆           ┆ i64       ┆          ┆   ┆           ┆ str       ┆ i64       ┆ ---       │\n",
       "│           ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆ i64       │\n",
       "╞═══════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ just the  ┆ billy     ┆ 72        ┆ false    ┆ … ┆ song of   ┆ 1977-11-1 ┆ 3         ┆ 378       │\n",
       "│ way you   ┆ joel      ┆           ┆          ┆   ┆ the year  ┆ 2         ┆           ┆           │\n",
       "│ are       ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ lonely    ┆ the black ┆ 73        ┆ false    ┆ … ┆ best rock ┆ 2011-11-1 ┆ 64        ┆ 210       │\n",
       "│ boy       ┆ keys      ┆           ┆          ┆   ┆ song      ┆ 2         ┆           ┆           │\n",
       "│ carry on  ┆ xxxtentac ┆ 75        ┆ true     ┆ … ┆ best      ┆ 2017-09-1 ┆ 95        ┆ 1         │\n",
       "│           ┆ ion       ┆           ┆          ┆   ┆ dance     ┆ 6         ┆           ┆           │\n",
       "│           ┆           ┆           ┆          ┆   ┆ recording ┆           ┆           ┆           │\n",
       "│ truth     ┆ lizzo     ┆ 1         ┆ true     ┆ … ┆ song of   ┆ 2019-05-1 ┆ 1         ┆ 903       │\n",
       "│ hurts     ┆           ┆           ┆          ┆   ┆ the year  ┆ 8         ┆           ┆           │\n",
       "│ youre     ┆ shania    ┆ 78        ┆ false    ┆ … ┆ best      ┆ 1998-02-1 ┆ 2         ┆ 903       │\n",
       "│ still the ┆ twain     ┆           ┆          ┆   ┆ country   ┆ 4         ┆           ┆           │\n",
       "│ one       ┆           ┆           ┆          ┆   ┆ song      ┆           ┆           ┆           │\n",
       "│ tears in  ┆ eric      ┆ 66        ┆ false    ┆ … ┆ record of ┆ 1992-02-0 ┆ 2         ┆ 351       │\n",
       "│ heaven    ┆ clapton   ┆           ┆          ┆   ┆ the year  ┆ 8         ┆           ┆           │\n",
       "│ you make  ┆ leo sayer ┆ 60        ┆ false    ┆ … ┆ best      ┆ 1976-10-2 ┆ 1         ┆ 231       │\n",
       "│ me feel   ┆           ┆           ┆          ┆   ┆ rhythm    ┆ 3         ┆           ┆           │\n",
       "│ like      ┆           ┆           ┆          ┆   ┆ blues     ┆           ┆           ┆           │\n",
       "│ dancing   ┆           ┆           ┆          ┆   ┆ song      ┆           ┆           ┆           │\n",
       "│ good life ┆ onerepubl ┆ 74        ┆ true     ┆ … ┆ best rap  ┆ 2009-11-2 ┆ 8         ┆ 630       │\n",
       "│           ┆ ic        ┆           ┆          ┆   ┆ song      ┆ 8         ┆           ┆           │\n",
       "│ after the ┆ earth     ┆ 67        ┆ false    ┆ … ┆ best      ┆ 1979-07-0 ┆ 2         ┆ 153       │\n",
       "│ love has  ┆ wind fire ┆           ┆          ┆   ┆ rhythm    ┆ 7         ┆           ┆           │\n",
       "│ gone      ┆           ┆           ┆          ┆   ┆ blues     ┆           ┆           ┆           │\n",
       "│           ┆           ┆           ┆          ┆   ┆ song      ┆           ┆           ┆           │\n",
       "│ lean on   ┆ bill      ┆ 70        ┆ false    ┆ … ┆ best      ┆ 1972-04-2 ┆ 1         ┆ 190       │\n",
       "│ me        ┆ withers   ┆           ┆          ┆   ┆ rhythm    ┆ 2         ┆           ┆           │\n",
       "│           ┆           ┆           ┆          ┆   ┆ blues     ┆           ┆           ┆           │\n",
       "│           ┆           ┆           ┆          ┆   ┆ song      ┆           ┆           ┆           │\n",
       "└───────────┴───────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv(\"../data/processed/fully_filled_rows.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (89, 16)\n",
      "┌───────────┬───────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ song_name ┆ artist    ┆ popularit ┆ explicit ┆ … ┆ category  ┆ first_cha ┆ billboard ┆ total_wee │\n",
      "│ ---       ┆ ---       ┆ y         ┆ ---      ┆   ┆ ---       ┆ rt_date   ┆ _peak     ┆ ks_on_cha │\n",
      "│ str       ┆ str       ┆ ---       ┆ bool     ┆   ┆ str       ┆ ---       ┆ ---       ┆ rt        │\n",
      "│           ┆           ┆ i64       ┆          ┆   ┆           ┆ str       ┆ i64       ┆ ---       │\n",
      "│           ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆ i64       │\n",
      "╞═══════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ someone   ┆ lewis     ┆ 87        ┆ false    ┆ … ┆ song of   ┆ 2019-05-2 ┆ 1         ┆ 1485      │\n",
      "│ you loved ┆ capaldi   ┆           ┆          ┆   ┆ the year  ┆ 5         ┆           ┆           │\n",
      "│ revenge   ┆ xxxtentac ┆ 87        ┆ true     ┆ … ┆ best      ┆ 2017-09-1 ┆ 77        ┆ 3         │\n",
      "│           ┆ ion       ┆           ┆          ┆   ┆ comedy    ┆ 6         ┆           ┆           │\n",
      "│           ┆           ┆           ┆          ┆   ┆ recording ┆           ┆           ┆           │\n",
      "│ every     ┆ the       ┆ 86        ┆ false    ┆ … ┆ song of   ┆ 1983-06-0 ┆ 1         ┆ 253       │\n",
      "│ breath    ┆ police    ┆           ┆          ┆   ┆ the year  ┆ 4         ┆           ┆           │\n",
      "│ you take  ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
      "│ lover     ┆ taylor    ┆ 85        ┆ false    ┆ … ┆ song of   ┆ 2019-08-3 ┆ 10        ┆ 253       │\n",
      "│           ┆ swift     ┆           ┆          ┆   ┆ the year  ┆ 1         ┆           ┆           │\n",
      "│ bad guy   ┆ billie    ┆ 84        ┆ false    ┆ … ┆ record of ┆ 2019-04-1 ┆ 1         ┆ 1225      │\n",
      "│           ┆ eilish    ┆           ┆          ┆   ┆ the year  ┆ 3         ┆           ┆           │\n",
      "│ …         ┆ …         ┆ …         ┆ …        ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ the lucky ┆ faith     ┆ 0         ┆ false    ┆ … ┆ best      ┆ 2006-04-0 ┆ 69        ┆ 45        │\n",
      "│ one       ┆ hill      ┆           ┆          ┆   ┆ country   ┆ 8         ┆           ┆           │\n",
      "│           ┆           ┆           ┆          ┆   ┆ song      ┆           ┆           ┆           │\n",
      "│ what a    ┆ the       ┆ 0         ┆ false    ┆ … ┆ song of   ┆ 1979-01-2 ┆ 1         ┆ 210       │\n",
      "│ fool      ┆ doobie    ┆           ┆          ┆   ┆ the year  ┆ 0         ┆           ┆           │\n",
      "│ believes  ┆ brothers  ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
      "│ if you    ┆ simply    ┆ 0         ┆ false    ┆ … ┆ best      ┆ 1989-05-0 ┆ 1         ┆ 253       │\n",
      "│ dont know ┆ red       ┆           ┆          ┆   ┆ rhythm    ┆ 6         ┆           ┆           │\n",
      "│ me by now ┆           ┆           ┆          ┆   ┆ blues     ┆           ┆           ┆           │\n",
      "│           ┆           ┆           ┆          ┆   ┆ song      ┆           ┆           ┆           │\n",
      "│ i feel    ┆ chaka     ┆ 0         ┆ false    ┆ … ┆ best      ┆ 1984-09-0 ┆ 3         ┆ 351       │\n",
      "│ for you   ┆ khan      ┆           ┆          ┆   ┆ rhythm    ┆ 8         ┆           ┆           │\n",
      "│           ┆           ┆           ┆          ┆   ┆ blues     ┆           ┆           ┆           │\n",
      "│           ┆           ┆           ┆          ┆   ┆ song      ┆           ┆           ┆           │\n",
      "│ walk      ┆ kodak     ┆ 0         ┆ true     ┆ … ┆ best rock ┆ 2022-10-2 ┆ 100       ┆ 1         │\n",
      "│           ┆ black     ┆           ┆          ┆   ┆ song      ┆ 2         ┆           ┆           │\n",
      "└───────────┴───────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir cuántas canciones populares quieres ver\n",
    "top_n = 20\n",
    "\n",
    "# Ordenar por popularidad descendente y seleccionar las primeras\n",
    "most_popular = df.sort(\"popularity\", descending=True)\n",
    "\n",
    "# Mostrar en notebook\n",
    "print(most_popular)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Process and Final Dataset\n",
    "\n",
    "## 1. Join Key\n",
    "\n",
    "The datasets are merged using a common key: `song_name`.  \n",
    "This field is standardized across datasets as follows:\n",
    "\n",
    "- From the **Spotify** dataset: derived from the `track_name` column  \n",
    "- From the **Grammys** dataset: derived from the `nominee` column  \n",
    "- From the **Billboard** dataset: derived from the `title` column  \n",
    "\n",
    "During the transformation step, these fields are cleaned by:\n",
    "- Converting to lowercase\n",
    "- Removing special characters\n",
    "- Replacing multiple spaces with a single space\n",
    "- Trimming leading/trailing spaces\n",
    "\n",
    "## 2. Merge Logic\n",
    "\n",
    "The merging is performed in the following order using `left joins`:\n",
    "\n",
    "1. **Spotify** is used as the base dataset. All songs in this dataset will be preserved.\n",
    "2. The **Grammys** dataset is joined on `song_name` using a left join.\n",
    "3. The **Billboard** dataset is then joined using the same key and join type.\n",
    "\n",
    "## 3. Resulting Structure\n",
    "\n",
    "The final merged dataset is written as a flat CSV file:  \n",
    "`/data/processed/final_dataset.csv`\n",
    "\n",
    "Each row represents a unique song (from Spotify), possibly enriched with:\n",
    "- Grammy award metadata (if the song won or was nominated)\n",
    "- Billboard chart performance (if the song entered the charts)\n",
    "\n",
    "## 4. Example Schema\n",
    "\n",
    "| song_name     | artist          | track_genre | popularity | tempo | nominee     | category           | grammy_year | billboard_peak | weeks_on_chart | first_year_on_chart |\n",
    "|---------------|------------------|--------------|------------|--------|--------------|---------------------|--------------|----------------|----------------|----------------------|\n",
    "| bad guy       | billie eilish    | pop          | 92         | 135.5  | bad guy       | record of the year  | 2019         | 1              | 15             | 2019                 |\n",
    "| 7 rings       | ariana grande    | pop          | 89         | 130.0  | 7 rings       | record of the year  | 2019         | 2              | 12             | 2019                 |\n",
    "| sunflower     | post malone      | hip hop      | 87         | 90.0   | sunflower     | record of the year  | 2019         | 3              | 14             | 2019                 |\n",
    "| unknown song  | unknown          | unknown      | 55         | 120.0  | null          | null                | null         | null           | null           | null                 |\n",
    "\n",
    "## 5. Purpose\n",
    "\n",
    "The final dataset is ready for analysis and visualization in BI tools such as Power BI, Looker, or Tableau. It allows you to:\n",
    "\n",
    "- Analyze the overlap between musical popularity and awards\n",
    "- Identify trends in genres, artists, or musical features\n",
    "- Visualize song performance across Spotify, Billboard, and Grammy records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset loaded into PostgreSQL.\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=770987404450-glri2v2td4808pcgq31uqii339ednft6.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Final dataset uploaded to Google Drive.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "DATA_PROCESSED = \"../data/processed\"\n",
    "CSV_FILENAME = \"final_dataset.csv\"\n",
    "CSV_FILE_PATH = f\"{DATA_PROCESSED}/{CSV_FILENAME}\"\n",
    "\n",
    "def load_and_store_final_dataset():\n",
    "    load_dotenv()\n",
    "\n",
    "    dbname   = os.getenv(\"DB_NAME\")\n",
    "    user     = os.getenv(\"DB_USER\")\n",
    "    password = os.getenv(\"DB_PASSWORD\")\n",
    "    host     = os.getenv(\"DB_HOST\")\n",
    "    port     = os.getenv(\"DB_PORT\")\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=dbname,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        host=host,\n",
    "        port=port\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Crear tabla con tipos y orden correcto\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS public.music_dataset (\n",
    "        song_name TEXT,\n",
    "        artist TEXT,\n",
    "        popularity INTEGER,\n",
    "        explicit BOOLEAN,\n",
    "        tempo FLOAT,\n",
    "        valence FLOAT,\n",
    "        energy FLOAT,\n",
    "        danceability FLOAT,\n",
    "        acousticness FLOAT,\n",
    "        duration_minutes FLOAT,\n",
    "        track_genre TEXT,\n",
    "        year INTEGER,\n",
    "        category TEXT,\n",
    "        first_chart_date TEXT,\n",
    "        billboard_peak INTEGER,\n",
    "        total_weeks_on_chart INTEGER\n",
    "    );\n",
    "    \"\"\"\n",
    "    cur.execute(create_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "    # Cargar datos desde el CSV\n",
    "    copy_query = \"\"\"\n",
    "    COPY public.music_dataset (\n",
    "        song_name, artist, popularity, explicit, tempo, valence, energy,\n",
    "        danceability, acousticness, duration_minutes, track_genre, year,\n",
    "        category, first_chart_date, billboard_peak, total_weeks_on_chart\n",
    "    )\n",
    "    FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "    \"\"\"\n",
    "    with open(CSV_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        cur.copy_expert(copy_query, f)\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"Final dataset loaded into PostgreSQL.\")\n",
    "\n",
    "    # Subir a Google Drive\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.LocalWebserverAuth()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    file_to_upload = drive.CreateFile({'title': CSV_FILENAME})\n",
    "    file_to_upload.SetContentFile(CSV_FILE_PATH)\n",
    "    file_to_upload.Upload()\n",
    "\n",
    "    print(\"Final dataset uploaded to Google Drive.\")\n",
    "\n",
    "load_and_store_final_dataset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
